{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def centroids(x,y):\n",
    "    c0 = x[np.where(y==0)].mean(axis=0)\n",
    "    c1 = x[np.where(y==1)].mean(axis=0)\n",
    "    c2 = x[np.where(y==2)].mean(axis=0)\n",
    "    return [c0,c1,c2]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected code defines a function called `centroids` that takes two arguments: `x` and `y`. `x` is a NumPy array containing the feature matrix of the iris dataset, and `y` is a NumPy array containing the target vector of the iris dataset.\n",
    "\n",
    "The `centroids` function calculates the mean of each feature for each class in the iris dataset. Specifically, it calculates the mean of the features for samples where the target variable `y` is equal to 0, 1, and 2, respectively. These means are then returned as a list of three arrays, where each array contains the mean of the features for one of the three classes.\n",
    "\n",
    "The resulting list of means can be used as the centroids for a k-means clustering algorithm, where each mean represents the center of one of the three clusters.\n",
    "\n",
    "Overall, the `centroids` function is a helper function that prepares the data for clustering by calculating the initial centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(c0,c1,c2,x):\n",
    "    p = np.zeros(x.shape[0], dtype=\"uint8\")\n",
    "    for i in range(x.shape[0]):\n",
    "        d = [((c0-x[i])**2).sum(),\n",
    "             ((c1-x[i])**2).sum(),\n",
    "             ((c2-x[i])**2).sum()]\n",
    "        p[i] = np.argmin(d)\n",
    "    return p\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selected code defines a function called `predict` that takes four arguments: `c0`, `c1`, `c2`, and `x`. `c0`, `c1`, and `c2` are NumPy arrays representing the centroids of three clusters, and `x` is a NumPy array representing the feature matrix of a dataset.\n",
    "\n",
    "The `predict` function assigns each sample in the feature matrix `x` to one of the three clusters based on the distance between the sample and the centroids of the clusters. Specifically, for each sample in `x`, the function calculates the squared Euclidean distance between the sample and each of the three centroids. The function then assigns the sample to the cluster with the closest centroid.\n",
    "\n",
    "The function returns a NumPy array `p` containing the cluster assignments for each sample in `x`. The values in `p` are integers representing the cluster assignments, where 0 represents the first cluster, 1 represents the second cluster, and 2 represents the third cluster.\n",
    "\n",
    "Overall, the `predict` function is a helper function that performs the clustering step of a k-means clustering algorithm. It takes the centroids of the clusters and a feature matrix as input, and returns the cluster assignments for each sample in the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [0 0 1 1 0 1 2 1 1 1 0 2 1 0 0 1 2 2 1 1 0 2 2 0 1 0 2 1 2 0]\n",
      "actual   : [0 0 1 2 0 1 2 1 1 1 0 2 2 0 0 2 2 2 1 1 0 2 2 0 1 0 2 1 2 0]\n",
      "test accuracy = 0.9000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = np.load(\"../data/iris/iris_features.npy\")\n",
    "y = np.load(\"../data/iris/iris_labels.npy\")\n",
    "N = 120\n",
    "x_train = x[:N]; x_test = x[N:]\n",
    "y_train = y[:N]; y_test = y[N:]\n",
    "c0, c1, c2 = centroids(x_train, y_train)\n",
    "p = predict(c0,c1,c2, x_test)\n",
    "nc = len(np.where(p == y_test)[0])\n",
    "nw = len(np.where(p != y_test)[0])\n",
    "acc = float(nc) / (float(nc)+float(nw))\n",
    "print(\"predicted:\", p)\n",
    "print(\"actual   :\", y_test)\n",
    "print(\"test accuracy = %0.4f\" % acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (1200, 4), y_train shape: (1200,)\n",
      "predicted: [0 0 1 1 0 1 2 1 1 1 0 2 2 0 0 1 2 2 1 1 0 2 2 0 1 0 2 1 2 0]\n",
      "actual   : [0 0 1 2 0 1 2 1 1 1 0 2 2 0 0 2 2 2 1 1 0 2 2 0 1 0 2 1 2 0]\n",
      "test accuracy = 0.9333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = np.load(\"../data/iris/iris_train_features_augmented.npy\")\n",
    "y = np.load(\"../data/iris/iris_train_labels_augmented.npy\")\n",
    "N = 120\n",
    "x_train = x\n",
    "y_train = y\n",
    "c0, c1, c2 = centroids(x_train, y_train)\n",
    "\n",
    "x_test = np.load(\"../data/iris/iris_test_features_augmented.npy\")\n",
    "y_test = np.load(\"../data/iris/iris_test_labels_augmented.npy\")\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "p = predict(c0,c1,c2, x_test)\n",
    "nc = len(np.where(p == y_test)[0])\n",
    "nw = len(np.where(p != y_test)[0])\n",
    "acc = float(nc) / (float(nc)+float(nw))\n",
    "print(\"predicted:\", p)\n",
    "print(\"actual   :\", y_test)\n",
    "print(\"test accuracy = %0.4f\" % acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - Pytorch and Tensorflow",
   "language": "python",
   "name": "python38-azureml-pt-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
